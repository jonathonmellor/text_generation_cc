{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Train Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Embedding\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import processed data, along with relevant supporting data for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names in the form date-time-word frequency minimum-sequence length-number of posts\n",
    "pickle_file = \"../processed_data/20200620-230848-50-4-5000\"\n",
    "\n",
    "with open(pickle_file, \"rb\") as f:\n",
    "    X, y, tokenizer, len_vocab, ngram_len = pickle.load(f) \n",
    "    \n",
    "print(\"Number of unique features\", len(np.unique(X)))\n",
    "print(\"Number of unique targets\", len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout prevents overfitting, as does adding a norm to final dense kernel (in theory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_embeddings = 100\n",
    "GRU_units = 256 #\n",
    "dropout = 0.4\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len_vocab, number_of_embeddings, input_length=ngram_len-1))\n",
    "if dropout > 0:\n",
    "    model.add(Dropout(dropout))\n",
    "model.add(GRU(GRU_units))\n",
    "model.add(Dense(len_vocab, activation='softmax', kernel_constraint=max_norm(2.)))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile network\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write callback section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../best_callbacks/weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=1, min_delta=0.005)\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_seq = X.shape[0]\n",
    "\n",
    "\n",
    "def build_model(X, y, v_split=0.2, number_of_epochs=10, \n",
    "                verbose=1, cbs=callbacks_list):\n",
    "    \"\"\"\n",
    "    Function to fit model\n",
    "    Using default parameters allows for simpler calling\n",
    "    \"\"\"\n",
    "    model.fit(X, y, validation_split=v_split, epochs=num_epochs, \n",
    "              verbose=verbose, callbacks=cbs)\n",
    "    \n",
    "    \n",
    "print(\"Total samples: \", len_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model, with callbacks ends far before max number of epochs (for small data) give the monitoring of val_loss, runs for longs if monitoring val_acc as distributions of final output change increasing acc but also increasing loss. (discrete vs contiuous metrics). Trying both val_loss and val_acc.\n",
    "\n",
    "\n",
    "# Model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "\n",
    "num_epochs = 20\n",
    "#batch_n = 50\n",
    "\n",
    "validation_split = 0.33\n",
    "\n",
    "build_model(X, y, v_split=validation_split, number_of_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that will convert from the embedded numbers to text with a number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integers\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        #TODO// More efficient way to do this than BF search\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = \"Reddit please help my wife has\"\n",
    "\n",
    "keras_embedder = tokenizer\n",
    "\n",
    "generate_seq(model, keras_embedder, ngram_len-1, test, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "write = False\n",
    "today = str(date.today()) + \"\\n\"\n",
    "\n",
    "\n",
    "\n",
    "tests = [\"My wife is not\", \"My husband has a\", \"My friend can\", \"My fiance did\", \n",
    "         \"My gf has not\", \"My girlfriend wants to\",\n",
    "         \"My girlfriend did not\", \"My boyfriend can\", \"My partner will\", \n",
    "         \"My wife (23F)\", \"My spouse is\", \"He does not\", \n",
    "         \"Help I\", \"Is there no\", \"I don't know\", \"My (18F) boyfriend\", \"There is a\",\n",
    "         \"Help, my (21F) boyfriend has\", \"My colleague keeps making posts\",\n",
    "         \"Me (52M) not sure about my\", \"I need help with\",\n",
    "         \"Does anyone know how I (41M)\",\n",
    "         \"Can I get\", \"My in laws can\",\n",
    "         \"Help reddit, my husband is\",\n",
    "         \"I can't keep going on\", \"aita for wanting\"]\n",
    "\n",
    "# How long should the generated sequence be\n",
    "length = 25\n",
    "\n",
    "\n",
    "if write:\n",
    "    f = open(\"../tests/GRU_test_outputs_final.txt\", \"a+\")\n",
    "    f.write(str(today) + \"4-5000\")\n",
    "    for each_test in tests:\n",
    "        test_output = generate_seq(model, keras_embedder, \n",
    "                                   ngram_len-1, each_test, length) + \"\\n\"\n",
    "        f.write(test_output)\n",
    "        print(test_output)\n",
    "    f.close()\n",
    "else:\n",
    "    for each_test in tests:\n",
    "        test_output = generate_seq(model, keras_embedder,\n",
    "                                   ngram_len-1, each_test, length) + \"\\n\"\n",
    "        print(test_output)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../saved_models/GRU-model-ngram{}-units{}-nseq{}.h5\".format(ngram_len, \n",
    "                                                                        GRU_units, \n",
    "                                                                        X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
