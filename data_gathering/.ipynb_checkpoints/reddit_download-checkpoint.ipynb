{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to request and download posts from praw (a reddit archive)'s api with the psaw wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import auth\n",
    "from psaw import PushshiftAPI\n",
    "import datetime as dt\n",
    "import time\n",
    "import progressbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to reddit with authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = auth.login()\n",
    "api = PushshiftAPI(reddit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select starting time for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch=int(dt.datetime(2017, 1, 1).timestamp()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_txt(filename_path, string):\n",
    "    \"\"\"Function to add a string to a text file\"\"\"\n",
    "    string = string + \"\\n\"\n",
    "    initfilename = filename\n",
    "    try:\n",
    "        with open(r\"{}.txt\".format(filename), \"a\") as f:\n",
    "            f.write(string) \n",
    "    except:\n",
    "        print(\"Failed to write to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_title(subreddit_name, num_posts, filename, path, start_time):\n",
    "    \"\"\"Function to get the titles from a specified time+subreddit and saving to file\"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    print(\"Total posts:\\t\", num_posts)\n",
    "    #converted to generator for memory management\n",
    "    request = (api.search_submissions(after=start_time,\n",
    "                            subreddit=subreddit,\n",
    "                            filter=['url', 'title'],\n",
    "                            limit=num_posts))\n",
    "    for index, submission in progressbar.progressbar(enumerate(request)):\n",
    "        title = submission.title\n",
    "        write_to_txt(filename, path, title)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_name = \"relationships\"\n",
    "num = 5000\n",
    "\n",
    "\n",
    "filename_path = \"../raw_data/{}_{}\".format(sub_name, num)\n",
    "\n",
    "scraper_title(sub_name, num, filename_path, start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
